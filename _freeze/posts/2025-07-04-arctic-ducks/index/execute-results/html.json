{
  "hash": "df177107a415bd4fd2da378bca231af9",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Arctic Ducks\"\nsubtitle: \"`polars` and `duckplyr`\"\ndescription: \"Interpreted Languages can have nice things too!\"\ndate: 07-04-2025\ncategories: [R, R-Package, Developer-Toolkit] \ncitation: \n    url: https://asenetcky.dev/posts/2025-05-20-thinking-in-projects/\ndraft: true \n---\n\n## What a Time to be Alive\n\nIn an era where AI is the all the rage, some of the most exciting things I have\nencountered and have been playing around with lately have been remixes on old\nfavorites.  I'm talking of course about working with dataframes.  One of \nmy favorites lately has been `polars` TODO: add link in python.\n\n...\n\nI've always admired DuckDB from a distance. Dabbling here or there.  Some \nfriends and colleagues of mine have thoroughly enjoyed it. I write a bunch\nof SQL code for work, and for me, it has always felt like that - work. I think\nthat actually has more to do with the locked down work environment with little\nto no tooling availible to anyone outside IT (like Data Scientists) than SQL\nitself so it is not *really* fair to SQL. However, because of the harsh \ndeveloper experience when dealing with SQL, I try to do  the absolute bare\nminimum I need to do and bail as fast as possible.  So DuckDB just never fell\ninto my lap - until now.\n\nEnter `duckplyr` TODO: link to posit post/tidyverse blog etc...\n\nTODO: Compare and Contrast the two\nTODO: Hammer the excellent bits, larger than memory analyses, lazy eval \nand opportunities for optimization.\n\n\n## Setup\n\n:::{.panel-tabset group=\"language\"}\n\n## R\n\nI'm using `renv` so setup might initially look something like\nthis in the console:\n\n```r\nrenv::install(\"duckplyr\", \"dplyr\", \"conflicted\")\n```\n\nand then at the top of our R scripts:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsuppressPackageStartupMessages({\n    library(conflicted)\n    library(duckplyr)\n    conflict_prefer(\"filter\", \"dplyr\") |> suppressMessages()\n    library(nanoparquet)\n})\n```\n:::\n\n\n## Python\nI'm using `uv` for python - so setup in the terminal would look \nsomething like this:\n\n```bash\n$ uv init\n$ uv add polars\n```\n\nand then at the top of our python scripts:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport polars as pl\n```\n:::\n\n\n:::\n\n\n#TODO use those parq files from the duckdb example.\n\n## Taking a Look\n\nRight up front I want to say this isn't going to be post where I pick\na favorite and sell you on it. I think having options, in multiple languages\nacross a few tools is good to have.  I intend to do a bit of exploring here\nand highlight why you might want to implement tools such as `duckplyr` and/or\n`polars`.\n\nAt the time of writing this, I am primarily an R programmer. I have spent more\ntime with python polars than anything duckdb-related, and quite a bit of time\nrecently with polars. Still, all of the time with python has been considerably \nless time compared to R. I have experimented a little bit with the duckdb cli\ntool in the past, but nothing more than an afternoon or two.  This is my first\nreal foray into working with the `duckplyr` package.  All this to say, that\nI am not an expert in either of these tools and I am likely not working\nwith them in the most idiomatic way. I'm mostly just here to crush\nparquet files and have a good time.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}